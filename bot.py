import os
import numpy as np
from pathlib import Path
from dotenv import load_dotenv
from aiogram import Bot, Dispatcher, Router, types
from aiogram.types import Message
from aiogram.filters import Command
from aiogram.utils.keyboard import ReplyKeyboardMarkup, KeyboardButton
from pydub import AudioSegment
import librosa
import soundfile as sf
import requests
from transformers import pipeline, AutoFeatureExtractor, AutoModelForAudioClassification
import torch

import logging
logging.basicConfig(level=logging.INFO)

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ===
load_dotenv()
BOT_TOKEN = os.getenv("BOT_TOKEN")  # –ü–æ–ª—É—á–∏—Ç–µ —É @BotFather
HF_TOKEN = os.getenv("HF_TOKEN", "")  # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: Hugging Face token –¥–ª—è Inference API
TEMP_DIR = Path("temp")
TEMP_DIR.mkdir(exist_ok=True)

bot = Bot(token=BOT_TOKEN)
dp = Dispatcher()
router = Router()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ML –º–æ–¥–µ–ª–∏ (–ª–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞)
ml_model = None
ml_processor = None
USE_ML = True  # –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–µ–∂–¥—É ML –∏ –ø—Ä–æ—Å—Ç—ã–º –∞–Ω–∞–ª–∏–∑–æ–º

# –ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞ ‚Äî –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
kb = ReplyKeyboardMarkup(
    keyboard=[[KeyboardButton(text="üé§ –ó–∞–ø–∏—à–∏—Ç–µ –ø–ª–∞—á —Ä–µ–±—ë–Ω–∫–∞")]],
    resize_keyboard=True,
    one_time_keyboard=False
)

@router.message(Command("start"))
async def cmd_start(message: Message):
    await message.answer(
        "üëã –ü—Ä–∏–≤–µ—Ç! –Ø ‚Äî *CryCheck*, –≤–∞—à –ø–æ–º–æ—â–Ω–∏–∫ –≤ –ø–æ–Ω–∏–º–∞–Ω–∏–∏ –¥–µ—Ç—Å–∫–æ–≥–æ –ø–ª–∞—á–∞.\n\n"
        "üëâ –ù–∞–∂–º–∏—Ç–µ –Ω–∞ –∑–Ω–∞—á–æ–∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –≤ Telegram –∏ –∑–∞–ø–∏—à–∏—Ç–µ 10‚Äì30 —Å–µ–∫ –ø–ª–∞—á–∞.\n"
        "–Ø –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –µ–≥–æ —Å –ø–æ–º–æ—â—å—é *AI –º–æ–¥–µ–ª–∏* –∏ –ø–æ–¥—Å–∫–∞–∂—É: *–≥–æ–ª–æ–¥, —É—Å—Ç–∞–ª–æ—Å—Ç—å –∏–ª–∏ –¥–∏—Å–∫–æ–º—Ñ–æ—Ä—Ç?*\n\n"
        "ü§ñ –ò—Å–ø–æ–ª—å–∑—É—é –±–µ—Å–ø–ª–∞—Ç–Ω—É—é ML –º–æ–¥–µ–ª—å –æ—Ç Hugging Face –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞\n"
        "üîí –í–∞—à–∏ –∞—É–¥–∏–æ–∑–∞–ø–∏—Å–∏ *–Ω–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è* ‚Äî –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ª–æ–∫–∞–ª—å–Ω–æ –∏ —Ñ–∞–π–ª—ã —É–¥–∞–ª—è—é—Ç—Å—è —Å—Ä–∞–∑—É.",
        parse_mode="Markdown",
        reply_markup=kb
    )

# === –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞: –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è ===
@router.message()
async def handle_voice(message: Message):
    if message.voice:
        voice = message.voice
        user_id = message.from_user.id
        file_id = voice.file_id

        ogg_path = TEMP_DIR / f"{user_id}_{file_id}.ogg"
        wav_path = TEMP_DIR / f"{user_id}_{file_id}.wav"

        try:
            # 1. –°–∫–∞—á–∏–≤–∞–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–µ
            await message.answer("üì• –ü–æ–ª—É—á–∞—é –∞—É–¥–∏–æ‚Ä¶")
            file = await bot.get_file(file_id)
            await bot.download_file(file.file_path, ogg_path)

            # 2. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ WAV (16kHz, –º–æ–Ω–æ)
            await message.answer("‚öôÔ∏è –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–≤—É–∫‚Ä¶")
            audio = AudioSegment.from_file(ogg_path, format="ogg")
            audio = audio.set_frame_rate(16000).set_channels(1)
            audio.export(wav_path, format="wav")

            # 3. –ê–Ω–∞–ª–∏–∑ —Å –ø–æ–º–æ—â—å—é ML –º–æ–¥–µ–ª–∏
            await message.answer("ü§ñ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å –ø–æ–º–æ—â—å—é AI‚Ä¶")
            if USE_ML:
                analysis = await analyze_cry_ml(wav_path, duration_sec=voice.duration)
            else:
                analysis = analyze_cry_simple(wav_path, duration_sec=voice.duration)

            # 4. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            await message.answer(
                f"üîç *–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω:*\n{analysis}",
                parse_mode="Markdown"
            )

        except Exception as e:
            await message.answer(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø–∏—Å–∞—Ç—å –µ—â—ë —Ä–∞–∑.")
            logging.error(f"–û—à–∏–±–∫–∞: {e}", exc_info=True)

        finally:
            # 5. –ß–∏—Å—Ç–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã ‚Äî –ü–†–ò–í–ê–¢–ù–û–°–¢–¨ –≤ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–µ!
            for p in [ogg_path, wav_path]:
                if p.exists():
                    p.unlink()

    else:
        await message.answer(
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ *–≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ* (–Ω–∞–∂–º–∏—Ç–µ –Ω–∞ –∑–Ω–∞—á–æ–∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ üé§).",
            parse_mode="Markdown",
            reply_markup=kb
        )

# === ML –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø–ª–∞—á–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Hugging Face ===
async def analyze_cry_ml(wav_path: Path, duration_sec: int) -> str:
    """
    –ê–Ω–∞–ª–∏–∑ –ø–ª–∞—á–∞ —Å –ø–æ–º–æ—â—å—é –±–µ—Å–ø–ª–∞—Ç–Ω–æ–π ML –º–æ–¥–µ–ª–∏ –æ—Ç Hugging Face.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç audio classification pipeline –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∞—É–¥–∏–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
    """
    try:
        global ml_model, ml_processor
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ —Å –ø–æ–º–æ—â—å—é librosa (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –º–æ–¥–µ–ª–µ–π)
        audio_array, sr = librosa.load(str(wav_path), sr=16000, duration=30)
        
        # –ï—Å–ª–∏ –∞—É–¥–∏–æ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ, –¥–æ–ø–æ–ª–Ω—è–µ–º —Ç–∏—à–∏–Ω–æ–π
        if len(audio_array) < sr * 2:  # –º–µ–Ω—å—à–µ 2 —Å–µ–∫—É–Ω–¥
            audio_array = np.pad(audio_array, (0, sr * 2 - len(audio_array)), mode='constant')
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
        if ml_model is None:
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∞—É–¥–∏–æ
                # –ú–æ–¥–µ–ª—å MIT/ast-finetuned-audioset-10-10-0.4593 —Ö–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è –æ–±—â–∏—Ö –∑–≤—É–∫–æ–≤
                model_name = "MIT/ast-finetuned-audioset-10-10-0.4593"
                logging.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ ML –º–æ–¥–µ–ª–∏: {model_name}")
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º pipeline –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è
                ml_model = pipeline(
                    "audio-classification",
                    model=model_name,
                    device=0 if torch.cuda.is_available() else -1
                )
                logging.info("ML –º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            except Exception as e:
                logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å ML –º–æ–¥–µ–ª—å: {e}. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑.")
                return analyze_cry_simple(wav_path, duration_sec)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∞—É–¥–∏–æ —Å –ø–æ–º–æ—â—å—é ML –º–æ–¥–µ–ª–∏
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç—ã –ø–æ 10 —Å–µ–∫—É–Ω–¥ –¥–ª—è –ª—É—á—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        segment_length = sr * 10
        segments = []
        for i in range(0, len(audio_array), segment_length):
            segment = audio_array[i:i+segment_length]
            if len(segment) >= sr * 2:  # –º–∏–Ω–∏–º—É–º 2 —Å–µ–∫—É–Ω–¥—ã
                segments.append(segment)
        
        if not segments:
            segments = [audio_array]
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Å–µ–≥–º–µ–Ω—Ç
        all_predictions = []
        for segment in segments:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –º–æ–¥–µ–ª–∏
            temp_segment_path = TEMP_DIR / f"segment_{hash(str(segment))}.wav"
            sf.write(str(temp_segment_path), segment, sr)
            
            try:
                predictions = ml_model(str(temp_segment_path))
                all_predictions.extend(predictions)
            finally:
                if temp_segment_path.exists():
                    temp_segment_path.unlink()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –∞—É–¥–∏–æ –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        features = extract_audio_features(audio_array, sr)
        
        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ML –∏ –∞—É–¥–∏–æ-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        analysis = interpret_ml_results(all_predictions, features, duration_sec)
        
        return analysis
        
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ ML –∞–Ω–∞–ª–∏–∑–∞: {e}", exc_info=True)
        # Fallback –Ω–∞ –ø—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑
        return analyze_cry_simple(wav_path, duration_sec)

def extract_audio_features(audio_array: np.ndarray, sr: int) -> dict:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—É–¥–∏–æ-–ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–ª–∞—á–∞"""
    features = {}
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    features['mean_amplitude'] = np.mean(np.abs(audio_array))
    features['std_amplitude'] = np.std(np.abs(audio_array))
    features['max_amplitude'] = np.max(np.abs(audio_array))
    
    # –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    spectral_centroids = librosa.feature.spectral_centroid(y=audio_array, sr=sr)[0]
    features['spectral_centroid_mean'] = np.mean(spectral_centroids)
    features['spectral_centroid_std'] = np.std(spectral_centroids)
    
    # Zero crossing rate (–ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–µ–∑–∫–æ—Å—Ç—å –∑–≤—É–∫–∞)
    zcr = librosa.feature.zero_crossing_rate(audio_array)[0]
    features['zcr_mean'] = np.mean(zcr)
    features['zcr_std'] = np.std(zcr)
    
    # MFCC (Mel-frequency cepstral coefficients) - –≤–∞–∂–Ω—ã–µ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∑–≤—É–∫–æ–≤
    mfccs = librosa.feature.mfcc(y=audio_array, sr=sr, n_mfcc=13)
    features['mfcc_mean'] = np.mean(mfccs, axis=1)
    
    # –¢–µ–º–ø (rhythm)
    tempo, _ = librosa.beat.beat_track(y=audio_array, sr=sr)
    features['tempo'] = tempo if tempo > 0 else 0
    
    return features

def interpret_ml_results(predictions: list, features: dict, duration_sec: int) -> str:
    """
    –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ML –º–æ–¥–µ–ª–∏ –∏ –∞—É–¥–∏–æ-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–∏—á–∏–Ω—ã –ø–ª–∞—á–∞
    """
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
    # –ò—â–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –∫—Ä–∏–∫–æ–º, –ø–ª–∞—á–µ–º, –¥–∏—Å–∫–æ–º—Ñ–æ—Ä—Ç–æ–º
    cry_indicators = []
    intensity_score = 0
    
    for pred in predictions:
        label = pred.get('label', '').lower()
        score = pred.get('score', 0)
        
        # –ò—â–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –º–µ—Ç–∫–∞—Ö
        if any(word in label for word in ['cry', 'crying', 'scream', 'shout', 'distress', 'pain']):
            cry_indicators.append((label, score))
            intensity_score += score
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∞—É–¥–∏–æ-–ø—Ä–∏–∑–Ω–∞–∫–∏
    spectral_centroid = features.get('spectral_centroid_mean', 0)
    zcr = features.get('zcr_mean', 0)
    mean_amp = features.get('mean_amplitude', 0)
    tempo = features.get('tempo', 0)
    
    # –õ–æ–≥–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–∏—á–∏–Ω—ã –ø–ª–∞—á–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    # –í—ã—Å–æ–∫–∏–π spectral centroid + –≤—ã—Å–æ–∫–∏–π ZCR = —Ä–µ–∑–∫–∏–π, –ø—Ä–æ–Ω–∑–∏—Ç–µ–ª—å–Ω—ã–π –∫—Ä–∏–∫ (–±–æ–ª—å/–¥–∏—Å–∫–æ–º—Ñ–æ—Ä—Ç)
    # –°—Ä–µ–¥–Ω–∏–π spectral centroid + —Ä–∏—Ç–º–∏—á–Ω–æ—Å—Ç—å = –≥–æ–ª–æ–¥
    # –ù–∏–∑–∫–∏–π-—Å—Ä–µ–¥–Ω–∏–π spectral centroid + –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –∞–º–ø–ª–∏—Ç—É–¥–∞ = —É—Å—Ç–∞–ª–æ—Å—Ç—å
    
    if spectral_centroid > 3000 and zcr > 0.15 and mean_amp > 0.3:
        # –†–µ–∑–∫–∏–π, –ø—Ä–æ–Ω–∑–∏—Ç–µ–ª—å–Ω—ã–π –∫—Ä–∏–∫
        return (
            "‚ö†Ô∏è *–í–µ—Ä–æ—è—Ç–Ω–æ ‚Äî –±–æ–ª—å –∏–ª–∏ –¥–∏—Å–∫–æ–º—Ñ–æ—Ä—Ç*\n"
            f"‚Äî –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ä–µ–∑–∫–æ–≥–æ, –ø—Ä–æ–Ω–∑–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫—Ä–∏–∫–∞ (AI —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {intensity_score*100:.1f}%)\n"
            "‚Äî –≤—ã—Å–æ–∫–∏–µ —á–∞—Å—Ç–æ—Ç—ã, —Ä–µ–∑–∫–∏–µ –ø–µ—Ä–µ—Ö–æ–¥—ã\n"
            "‚Äî –Ω–µ —É—Å–ø–æ–∫–∞–∏–≤–∞–µ—Ç—Å—è –ø—Ä–∏ —É–∫–∞—á–∏–≤–∞–Ω–∏–∏\n"
            "üí° *–ü—Ä–æ–≤–µ—Ä—å—Ç–µ: –∂–∏–≤–æ—Ç–∏–∫, –ø–æ–¥–≥—É–∑–Ω–∏–∫, —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É. –ü—Ä–∏ —Å–æ–º–Ω–µ–Ω–∏—è—Ö ‚Äî –≤—ã–∑–æ–≤–∏—Ç–µ –≤—Ä–∞—á–∞.*"
        )
    elif 2000 < spectral_centroid < 3000 and 0.05 < zcr < 0.12 and duration_sec < 30:
        # –†–∏—Ç–º–∏—á–Ω—ã–π, —É–º–µ—Ä–µ–Ω–Ω—ã–π –ø–ª–∞—á
        return (
            "üçº *–í–µ—Ä–æ—è—Ç–Ω–æ ‚Äî –≥–æ–ª–æ–¥*\n"
            f"‚Äî –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ä–∏—Ç–º–∏—á–Ω–æ–≥–æ –ø–ª–∞—á–∞ (AI —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {intensity_score*100:.1f}%)\n"
            "‚Äî –ø–ª–∞—á –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ, —Ä–∏—Ç–º–∏—á–Ω—ã–π\n"
            "‚Äî —Å—Ä–µ–¥–Ω–∏–µ —á–∞—Å—Ç–æ—Ç—ã, —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –ø–∞—É–∑—ã\n"
            "üí° *–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∫–æ—Ä–º–∏—Ç—å ‚Äî –¥–∞–∂–µ –µ—Å–ª–∏ ¬´–ø–æ –≤—Ä–µ–º–µ–Ω–∏ –µ—â—ë —Ä–∞–Ω–æ¬ª.*"
        )
    elif spectral_centroid < 2500 and zcr < 0.1:
        # –ú—è–≥–∫–∏–π, –∑–∞—Ç—É—Ö–∞—é—â–∏–π –ø–ª–∞—á
        return (
            "üò¥ *–í–µ—Ä–æ—è—Ç–Ω–æ ‚Äî —É—Å—Ç–∞–ª–æ—Å—Ç—å / –ø–µ—Ä–µ–≤–æ–∑–±—É–∂–¥–µ–Ω–∏–µ*\n"
            f"‚Äî –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ —É—Å—Ç–∞–ª–æ—Å—Ç–∏ (AI —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {intensity_score*100:.1f}%)\n"
            "‚Äî –ø–ª–∞—á –Ω–∞—Ä–∞—Å—Ç–∞–µ—Ç –º–µ–¥–ª–µ–Ω–Ω–æ, –∑–∞—Ç–µ–º –∑–∞—Ç—É—Ö–∞–µ—Ç\n"
            "‚Äî –Ω–∏–∑–∫–∏–µ-—Å—Ä–µ–¥–Ω–∏–µ —á–∞—Å—Ç–æ—Ç—ã, –ø–ª–∞–≤–Ω—ã–µ –ø–µ—Ä–µ—Ö–æ–¥—ã\n"
            "üí° *–ü—Ä–∏–≥–ª—É—à–∏—Ç–µ —Å–≤–µ—Ç –∏ –∑–≤—É–∫–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –±–µ–ª—ã–π —à—É–º –∏ –º–µ–¥–ª–µ–Ω–Ω–æ–µ —É–∫–∞—á–∏–≤–∞–Ω–∏–µ.*"
        )
    else:
        # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        if mean_amp > 0.25 and duration_sec > 20:
            return (
                "ü§î *–°–º–µ—à–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏*\n"
                f"‚Äî AI –∞–Ω–∞–ª–∏–∑ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–ª–æ–∂–Ω—É—é –∫–∞—Ä—Ç–∏–Ω—É (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {intensity_score*100:.1f}%)\n"
                "‚Äî –≤–æ–∑–º–æ–∂–Ω–æ, –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏—á–∏–Ω –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ\n"
                "üí° *–ü–æ–ø—Ä–æ–±—É–π—Ç–µ: –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–¥–≥—É–∑–Ω–∏–∫, –ø–æ–∫–æ—Ä–º–∏—Ç—å, —É–∫–∞—á–∞—Ç—å. –ù–∞–±–ª—é–¥–∞–π—Ç–µ –∑–∞ —Ä–µ–∞–∫—Ü–∏–µ–π.*"
            )
        else:
            return (
                "üîç *–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω*\n"
                f"‚Äî AI –æ–±—Ä–∞–±–æ—Ç–∞–ª –∞—É–¥–∏–æ (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {intensity_score*100:.1f}%)\n"
                "‚Äî –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ–æ–¥–Ω–æ–∑–Ω–∞—á–Ω—ã, —Ç—Ä–µ–±—É–µ—Ç—Å—è –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö\n"
                "üí° *–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø–∏—Å–∞—Ç—å –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ (20-30 —Å–µ–∫) –¥–ª—è –ª—É—á—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.*"
            )

# === –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø–ª–∞—á–∞ (fallback –±–µ–∑ ML) ===
def analyze_cry_simple(wav_path: Path, duration_sec: int) -> str:
    """
    MVP-–∞–Ω–∞–ª–∏–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ:
    - –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    - –∞–º–ø–ª–∏—Ç—É–¥–Ω—ã—Ö –≤—Å–ø–ª–µ—Å–∫–æ–≤ (¬´—Ä–µ–∑–∫–æ—Å—Ç—å¬ª)
    - —Å—Ä–µ–¥–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏
    
    –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –≤–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏—è: Dunstan Baby Language, Newman et al. (2021)
    """
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ –∫–∞–∫ –º–∞—Å—Å–∏–≤ (–º–æ–Ω–æ)
        audio = AudioSegment.from_wav(wav_path)
        samples = np.array(audio.get_array_of_samples())
        if audio.channels == 2:
            samples = samples.reshape((-1, 2)).mean(axis=1)  # —Å–≤–æ–¥–∏–º –∫ –º–æ–Ω–æ

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        samples = samples / np.max(np.abs(samples) + 1e-6)

        # –ü—Ä–∏–∑–Ω–∞–∫–∏:
        mean_amp = np.mean(np.abs(samples))
        std_amp = np.std(np.abs(samples))
        peak_amp = np.max(np.abs(samples))
        # –°—á–∏—Ç–∞–µ–º "–≤—Å–ø–ª–µ—Å–∫–∏" ‚Äî –º–æ–º–µ–Ω—Ç—ã, –≥–¥–µ –∞–º–ø–ª–∏—Ç—É–¥–∞ —Ä–µ–∑–∫–æ —Ä–∞—Å—Ç—ë—Ç (> 3œÉ)
        diff = np.abs(np.diff(np.abs(samples)))
        spikes = np.sum(diff > 3 * np.std(diff))

        # –ü—Ä–∞–≤–∏–ª–∞ (—É–ø—Ä–æ—â—ë–Ω–Ω–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞)
        if duration_sec < 20 and mean_amp > 0.2 and spikes < 5:
            # –ö–æ—Ä–æ—Ç–∫–∏–π, —É–º–µ—Ä–µ–Ω–Ω–æ –≥—Ä–æ–º–∫–∏–π, –ø–ª–∞–≤–Ω—ã–µ –ø–µ—Ä–µ—Ö–æ–¥—ã
            return (
                "üçº *–í–µ—Ä–æ—è—Ç–Ω–æ ‚Äî –≥–æ–ª–æ–¥*\n"
                "‚Äî –ø–ª–∞—á –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ,\n"
                "‚Äî —Ä–∏—Ç–º–∏—á–Ω—ã–π, —Å –ø–∞—É–∑–∞–º–∏ (~2 —Å–µ–∫ –Ω–∞ —Ü–∏–∫–ª),\n"
                "üí° *–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∫–æ—Ä–º–∏—Ç—å ‚Äî –¥–∞–∂–µ –µ—Å–ª–∏ ¬´–ø–æ –≤—Ä–µ–º–µ–Ω–∏ –µ—â—ë —Ä–∞–Ω–æ¬ª.*"
            )
        elif duration_sec > 40 and mean_amp > 0.3 and spikes > 10:
            # –î–æ–ª–≥–∏–π, –≥—Ä–æ–º–∫–∏–π, –º–Ω–æ–≥–æ —Ä–µ–∑–∫–∏—Ö –≤—Å–ø–ª–µ—Å–∫–æ–≤
            return (
                "‚ö†Ô∏è *–í–µ—Ä–æ—è—Ç–Ω–æ ‚Äî –±–æ–ª—å –∏–ª–∏ –¥–∏—Å–∫–æ–º—Ñ–æ—Ä—Ç*\n"
                "‚Äî —Ä–µ–∑–∫–∏–µ –≤—Å–ø–ª–µ—Å–∫–∏, –∫—Ä–∏–∫ ¬´–Ω–∞ –≤—ã–¥–æ—Ö–µ¬ª,\n"
                "‚Äî –Ω–µ —É—Å–ø–æ–∫–∞–∏–≤–∞–µ—Ç—Å—è –ø—Ä–∏ —É–∫–∞—á–∏–≤–∞–Ω–∏–∏,\n"
                "üí° *–ü—Ä–æ–≤–µ—Ä—å—Ç–µ: –∂–∏–≤–æ—Ç–∏–∫, –ø–æ–¥–≥—É–∑–Ω–∏–∫, —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É. –ü—Ä–∏ —Å–æ–º–Ω–µ–Ω–∏—è—Ö ‚Äî –≤—ã–∑–æ–≤–∏—Ç–µ –≤—Ä–∞—á–∞.*"
            )
        else:
            # –í—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ ‚Äî —É—Å—Ç–∞–ª–æ—Å—Ç—å/–ø–µ—Ä–µ–≤–æ–∑–±—É–∂–¥–µ–Ω–∏–µ
            return (
                "üò¥ *–í–µ—Ä–æ—è—Ç–Ω–æ ‚Äî —É—Å—Ç–∞–ª–æ—Å—Ç—å / –ø–µ—Ä–µ–≤–æ–∑–±—É–∂–¥–µ–Ω–∏–µ*\n"
                "‚Äî –ø–ª–∞—á –Ω–∞—Ä–∞—Å—Ç–∞–µ—Ç –º–µ–¥–ª–µ–Ω–Ω–æ, –∑–∞—Ç–µ–º –∑–∞—Ç—É—Ö–∞–µ—Ç,\n"
                "‚Äî —Ä–µ–±—ë–Ω–æ–∫ —Ç—Ä—ë—Ç –≥–ª–∞–∑–∞/–∑–µ–≤–∞–µ—Ç,\n"
                "üí° *–ü—Ä–∏–≥–ª—É—à–∏—Ç–µ —Å–≤–µ—Ç –∏ –∑–≤—É–∫–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –±–µ–ª—ã–π —à—É–º –∏ –º–µ–¥–ª–µ–Ω–Ω–æ–µ —É–∫–∞—á–∏–≤–∞–Ω–∏–µ.*"
            )

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
        return "‚ùì –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–ª–∞—á. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø–∏—Å–∞—Ç—å –∫–æ—Ä–æ—á–µ –∏ —á—ë—Ç—á–µ."

# === –ó–∞–ø—É—Å–∫ ===
dp.include_router(router)

if __name__ == "__main__":
    print("üöÄ CryCheck –±–æ—Ç –∑–∞–ø—É—â–µ–Ω! –û—Ç–∫—Ä–æ–π—Ç–µ Telegram –∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ /start")
    import asyncio
    asyncio.run(dp.start_polling(bot))